<video width="100%" controls muted>
  <source src="assets/demo.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

# ğŸ® Multimodal Game Recommendation System

## ğŸ¥ Video Demo
> **Quick walkthrough of the system (UI + recommendations)**

ğŸ“‚ `assets/demo.mp4`  
â–¶ï¸ [Click here to watch the demo](assets/demo.mp4)

---

## ğŸ“Œ Project Overview

An **AI-powered content-based video game recommendation system** that leverages **multimodal deep learning (text + images)** and **cross-modal retrieval using CLIP** to recommend similar games â€” even in **cold-start scenarios**.

Traditional recommendation systems rely heavily on user ratings or interaction history, which often fail for **new users** or **new games**.  
This project solves that problem by using **game content itself**:

- ğŸ“„ **Text** â†’ Game descriptions & genres  
- ğŸ–¼ï¸ **Images** â†’ Game posters  
- ğŸ”€ **Multimodal embeddings** â†’ Semantic similarity  
- ğŸ”— **CLIP** â†’ Image-to-text recommendation  

The final system is deployed as an **interactive Streamlit web application**.

---

## ğŸ§  Key Features

- âœ… Content-based recommendations (no user data required)
- âœ… Multimodal learning (text + image)
- âœ… Cross-modal image â†’ game search using CLIP
- âœ… Cold-start friendly
- âœ… Scalable embedding-based design
- âœ… Interactive Streamlit UI
- âœ… Production-ready deployment setup

---

## ğŸ—ï¸ System Architecture

### Stage 1: Prototype & Validation
- Small dataset to verify pipeline correctness

### Stage 2: Multimodal Embedding Generation
- **BERT** â†’ Text embeddings  
- **ResNet50** â†’ Image embeddings  
- **Fusion** â†’ Final game embedding  

### Stage 3: Cross-Modal CLIP Retrieval
- CLIP text embeddings (offline)
- Image â†’ Text similarity search

### Deployment
- **Streamlit**
- **Render**

---

## ğŸ” Recommendation Modes

### 1ï¸âƒ£ Text-Based Recommendation
- Select a game
- System finds similar games using **multimodal embeddings**
- Similarity measured using **cosine similarity**

### 2ï¸âƒ£ Image-Based Recommendation (CLIP)
- Upload a game image
- CLIP encodes the image
- Matches it against CLIP text embeddings of games
- Returns visually and semantically similar games

---

## ğŸ§ª Technologies Used

### ğŸ”¹ Core ML / DL
- **BERT** â€“ Text understanding
- **ResNet50** â€“ Visual feature extraction
- **CLIP (ViT-B/32)** â€“ Cross-modal learning
- **Transfer Learning** â€“ Frozen encoders

### ğŸ”¹ Libraries
- `numpy`, `pandas`
- `scikit-learn`
- `torch`, `torchvision`
- `clip (OpenAI)`
- `streamlit`

### ğŸ”¹ Deployment
- **Render**
- Lightweight runtime (no TensorFlow required)

---

## ğŸ“ Repository Structure

```text
â”œâ”€â”€ app.py                         # Streamlit application
â”œâ”€â”€ model.ipynb                    # Stage-2 embedding generation
â”œâ”€â”€ build_clip_text_embeddings.py  # Stage-3 CLIP text embeddings
â”œâ”€â”€ game_embeddings.npy            # Final multimodal embeddings
â”œâ”€â”€ clip_text_embeddings.npy       # CLIP text embeddings
â”œâ”€â”€ game_metadata.csv              # Clean metadata used by app
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ banner.jpg                 # UI banner
â”‚   â””â”€â”€ demo.mp4                   # Demo video
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

##ğŸš€ How to Run Locally
```
1ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

2ï¸âƒ£ Run the App
streamlit run app.py



ğŸ§  Design Decisions

Precomputed embeddings â†’ Fast inference

No heavy ML libraries at runtime â†’ Lightweight deployment

Cosine similarity â†’ Ideal for high-dimensional embeddings

CLIP â†’ Enables image-based recommendation without labels

Clean separation of stages â†’ Industry-style ML system design


ğŸ‘¤ Author

Dhruv
IMSc â€“ Quantitative Economics & Data Science
BIT Mesra
